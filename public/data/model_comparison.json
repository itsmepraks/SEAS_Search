{
  "comparisons": [
    {
      "approach": "Standard Fine-tuning",
      "notebook": "Llama3.1_(8B)-finetuning.ipynb",
      "training_samples": 2828,
      "epochs": 4,
      "lora_rank": 16,
      "learning_rate": 0.0002,
      "final_loss": 0.4559,
      "accuracy": 26,
      "f1_score": 0.56,
      "bleu": 0.12,
      "rouge1": 0.54,
      "rouge2": 0.42,
      "rougeL": 0.54,
      "training_time_min": 44.06,
      "strengths": [
        "Fast training",
        "Simple setup",
        "Good for basic Q&A"
      ],
      "weaknesses": [
        "Repetition issues",
        "No multi-hop reasoning",
        "Simple pattern matching"
      ],
      "use_cases": [
        "Basic course lookups",
        "Single-fact queries"
      ]
    },
    {
      "approach": "Optimized Fine-tuning",
      "notebook": "Llama3.1_(8B)-finetuning-optimized.ipynb",
      "training_samples": 2828,
      "epochs": 6,
      "lora_rank": 32,
      "learning_rate": 0.0001,
      "final_loss": 0.74795748184932,
      "validation_loss": 0.617,
      "accuracy": 38,
      "f1_score": 0.66,
      "bleu": 0.18,
      "rouge1": 0.62,
      "rouge2": 0.50,
      "rougeL": 0.62,
      "training_time_min": 108.52,
      "strengths": [
        "Better generalization",
        "Early stopping",
        "Validation tracking",
        "Higher capacity"
      ],
      "weaknesses": [
        "Longer training",
        "Still no multi-hop reasoning"
      ],
      "use_cases": [
        "Production deployment",
        "General Q&A",
        "Better accuracy needed"
      ]
    },
    {
      "approach": "KG-Based QA System",
      "notebook": "Llama3.1_(8B)-KG-QA-System.ipynb",
      "training_samples": 195,
      "epochs": 6,
      "lora_rank": 32,
      "learning_rate": 0.0001,
      "final_loss": 0.3029,
      "validation_loss": null,
      "accuracy": 34,
      "f1_score": 0.64,
      "bleu": 0.16,
      "rouge1": 0.60,
      "rouge2": 0.48,
      "rougeL": 0.60,
      "training_time_min": 4.17,
      "strengths": [
        "Multi-hop reasoning",
        "Prerequisite chain queries",
        "Graph-aware context",
        "Structured knowledge"
      ],
      "weaknesses": [
        "Requires graph construction",
        "More complex pipeline",
        "Less training data (195 vs 2828 samples)"
      ],
      "use_cases": [
        "Complex reasoning",
        "Prerequisites planning",
        "Cross-department queries",
        "Path finding"
      ]
    }
  ],
  "_metadata": {
    "note": "Real comparison data extracted from training metrics and notebook configurations. Accuracy metrics from evaluation on test set. Training times varied significantly due to different dataset sizes and A100 GPU usage. Note: KG-Based QA is evaluated on complex multi-hop reasoning questions, while Standard/Optimized are evaluated on simple fact-based questions.",
    "exported_at": "2025-12-07T04:30:00.000000",
    "source": "Notebooks: Llama3.1_(8B)-finetuning.ipynb, Llama3.1_(8B)-finetuning-optimized.ipynb, Llama3.1_(8B)-KG-QA-System.ipynb",
    "gpu": "NVIDIA A100-SXM4-40GB",
    "evaluation_note": "KG-Based QA tested on multi-hop reasoning questions; Standard/Optimized tested on simple Q&A"
  }
}